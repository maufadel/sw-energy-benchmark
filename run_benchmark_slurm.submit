#!/bin/bash
#SBATCH --time=600
#SBATCH --job-name=energy_bench
#SBATCH --ntasks=1
#SBATCH --nodes=1
#SBATCH --account=init
#SBATCH --gres=gpu:1
#SBATCH --output=/cluster/home/fues/sw-energy-benchmark/log/%j_%N__energy_bench.out
#SBATCH --error=/cluster/home/fues/sw-energy-benchmark/log/%j_%N__energy_bench.err

# Set the root folder for the project
ROOT_FOLDER="/cluster/home/fues/sw-energy-benchmark"
UV_PATH="/cluster/home/fues/.local/bin/uv"

# --- Script Start ---
# SLURM provides $SLURM_JOB_ID as a unique identifier for each job.
echo "[$(date)] Starting Job ID: $SLURM_JOB_ID"

# Create a job-specific virtual environment in a temporary directory
VENV_DIR="/tmp/sw-energy-benchmark-venv-$SLURM_JOB_ID"
mkdir -p "$VENV_DIR"
"$UV_PATH" venv "$VENV_DIR"
source "$VENV_DIR/bin/activate"

# Set up a trap to clean up the virtual environment on exit
trap 'rm -rf -- "$VENV_DIR"' EXIT

# Install dependencies into the virtual environment
#"$UV_PATH" pip sync "$ROOT_FOLDER/requirements.txt"

"$UV_PATH" pip install -r "$ROOT_FOLDER/requirements.txt"

# Discover the correct library path within the venv
# --- START DEBUGGING BLOCK ---
echo "--- [DEBUG] Verifying library installation ---"

# Define the site-packages path for easier access
SITE_PACKAGES="$VENV_DIR/lib/python3.11/site-packages"

echo "[DEBUG] VENV_DIR is: $VENV_DIR"
echo "[DEBUG] Searching for libcusparseLt.so.0 in the entire venv..."

# Search the entire virtual environment for the missing library
find "$VENV_DIR" -name "libcusparseLt.so.0"

echo "[DEBUG] Listing contents of the expected directory..."
# List the contents of the directory where the library SHOULD be
ls -l "$SITE_PACKAGES/nvidia/cusparse/lib/"

echo "[DEBUG] Current LD_LIBRARY_PATH is: $LD_LIBRARY_PATH"
echo "--- [DEBUG] End of verification ---"


export LD_LIBRARY_PATH="$SITE_PACKAGES/nvidia/cusparselt/lib:$SITE_PACKAGES/nvidia/cublas/lib:$SITE_PACKAGES/nvidia/cusparse/lib:$SITE_PACKAGES/nvidia/cudnn/lib:$LD_LIBRARY_PATH"


# Set up a job-specific Hugging Face home to isolate model downloads
HF_HOME_DIR="/tmp/hf_home-$SLURM_JOB_ID"
mkdir -p "$HF_HOME_DIR"
export HF_HOME="$HF_HOME_DIR"

# Set up a trap to clean up the virtual environment and HF home on exit
trap 'rm -rf -- "$VENV_DIR" "$HF_HOME_DIR"' EXIT


# --- Create a unique results directory for this specific job ---
# This prevents multiple jobs from overwriting each other's results.
JOB_RESULTS_FOLDER="$ROOT_FOLDER/results/$SLURM_JOB_ID"
mkdir -p "$JOB_RESULTS_FOLDER"
echo "[$(date)] Results will be stored in: $JOB_RESULTS_FOLDER"

# Define the path for the system info file within the unique job folder
RESULTS_FILE="$JOB_RESULTS_FOLDER/system_info.txt"

# ---------------------------------------
# Register system info.
# ---------------------------------------
echo "[$(date)] Registering system info..."

# The > operator creates and overwrites the file with the first command's output.
# The >> operator appends the output of subsequent commands to the same file.

echo "lscpu" > "$RESULTS_FILE"
lscpu >> "$RESULTS_FILE"
echo -e "\n" >> "$RESULTS_FILE"

echo "nvidia-smi" >> "$RESULTS_FILE"
nvidia-smi >> "$RESULTS_FILE"
echo -e "\n" >> "$RESULTS_FILE"

echo "free -h" >> "$RESULTS_FILE"
free -h >> "$RESULTS_FILE"
echo -e "\n" >> "$RESULTS_FILE"

echo "df -h" >> "$RESULTS_FILE"
df -h >> "$RESULTS_FILE"
echo -e "\n" >> "$RESULTS_FILE"

echo "[$(date)] System info registered in $RESULTS_FILE"

# ---------------------------------------
# Run the Python scripts for language
# You can redirect the output of each script to a specific file in your job's result folder
echo "[$(date)] Running llm_server_optimized.py..."
#srun python "$ROOT_FOLDER/language/llm_server_optimized.py" "$JOB_RESULTS_FOLDER" > "$JOB_RESULTS_FOLDER/llm_server_optimized.out"
srun --export=ALL python "$ROOT_FOLDER/language/llm_server_optimized.py" "$JOB_RESULTS_FOLDER" > "$JOB_RESULTS_FOLDER/llm_server_optimized.out"

echo "[$(date)] Running llm_batch_optimized.py..."
#srun python "$ROOT_FOLDER/language/llm_batch_optimized.py" "$JOB_RESULTS_FOLDER" > "$JOB_RESULTS_FOLDER/llm_batch_optimized.out"
srun --export=ALL python "$ROOT_FOLDER/language/llm_batch_optimized.py" "$JOB_RESULTS_FOLDER" > "$JOB_RESULTS_FOLDER/llm_batch_optimized.out"

# ---------------------------------------
# Run the Python scripts for vision
#echo "[$(date)] Running resnet50_batch.py..."
#python vision/resnet50_batch.py > "$JOB_RESULTS_FOLDER/resnet50_batch.out"
#echo "[$(date)] Running resnet50_server.py..."
#python vision/resnet50_server.py > "$JOB_RESULTS_FOLDER/resnet50_server.out"

# ---------------------------------------
# Run the Python scripts for tabular
#echo "[$(date)] Running tabular_batch.py..."
#python tabular/tabular_batch.py > "$JOB_RESULTS_FOLDER/tabular_batch.out"
#echo "[$(date)] Running tabular_server.py..."
#python tabular/tabular_server.py > "$JOB_RESULTS_FOLDER/tabular_server.out"


echo "[$(date)] Job Finished"
