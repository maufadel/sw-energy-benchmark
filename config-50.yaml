# GPU configuration
CUDA_VISIBLE_DEVICES: "0"

# Benchmark settings
ITERATIONS: 5
MAX_TEST_DURATION: 300  # 5 minutes in seconds

# Server experiment settings
LAMBDA_QPS_ARRAY:
  - 0.014467592592592592
  - 0.38580246913580245

# LLM models to benchmark
LLM_MODELS:
  - "Qwen/Qwen2.5-14B-Instruct-1M"
  - "Qwen/Qwen2.5-14B-Instruct"
  - "upstage/solar-pro-preview-instruct"
  - "internlm/internlm2_5-20b-chat"
  - "deepseek-ai/DeepSeek-R1-Distill-Qwen-14B"
  - "tiiuae/Falcon3-7B-Instruct"
  - "google/gemma-2-27b-it"
  - "tiiuae/Falcon3-10B-Instruct"
  - "Qwen/Qwen2.5-7B-Instruct"
  - "microsoft/Phi-3-medium-4k-instruct"
  - "nvidia/AceInstruct-7B"
  - "internlm/internlm2_5-7b-chat"
  - "Qwen/Qwen2.5-7B-Instruct-1M"
  - "microsoft/Phi-3-small-8k-instruct"
  - "Qwen/Qwen2.5-Coder-14B-Instruct"
  - "google/gemma-2-9b-it"
  - "microsoft/Phi-3-medium-128k-instruct"
  - "NousResearch/DeepHermes-3-Mistral-24B-Preview"
  - "microsoft/Phi-3-small-128k-instruct"
  - "CohereForAI/c4ai-command-r7b-12-2024"
  - "ibm-granite/granite-3.2-8b-instruct"
  - "ibm-granite/granite-3.1-8b-instruct"
  - "microsoft/phi-4"
  - "nvidia/AceMath-7B-Instruct"
  - "mistralai/Mistral-Small-Instruct-2409"
  - "01-ai/Yi-1.5-9B-Chat"
  - "microsoft/Phi-4-mini-instruct"
  - "rhymes-ai/Aria"
  - "cognitivecomputations/dolphin-2.9.2-Phi-3-Medium"
  - "cognitivecomputations/dolphin-2.9.2-Phi-3-Medium-abliterated"
  - "speakleash/Bielik-11B-v2.3-Instruct"
  - "microsoft/Phi-3.5-mini-instruct"
  - "tiiuae/Falcon3-Mamba-7B-Instruct"
  - "Qwen/Qwen2.5-Coder-7B-Instruct"
  - "speakleash/Bielik-11B-v2.2-Instruct"
  - "Qwen/Qwen2-7B-Instruct"
  - "microsoft/Phi-3-mini-4k-instruct"
  - "speakleash/Bielik-11B-v2.1-Instruct"
  - "mistralai/Mistral-Small-24B-Base-2501"
  - "mlabonne/NeuralDaredevil-8B-abliterated"
  - "Qwen/Qwen2.5-3B-Instruct"
  - "tiiuae/Falcon3-3B-Instruct"
  - "Qwen/Qwen2-VL-7B-Instruct"
  - "allenai/Llama-3.1-Tulu-3-8B-DPO"
  - "microsoft/Phi-3-mini-128k-instruct"
  - "allenai/Llama-3.1-Tulu-3-8B"
  - "cognitivecomputations/dolphin-2.9.1-yi-1.5-9b"
  - "cognitivecomputations/Dolphin3.0-Llama3.1-8B"
  - "cognitivecomputations/dolphin-2.9.3-mistral-nemo-12b"
  - "NousResearch/Hermes-2-Theta-Llama-3-8B"
